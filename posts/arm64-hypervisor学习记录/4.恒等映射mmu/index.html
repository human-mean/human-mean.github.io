<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>4.恒等映射MMU | 嵌入式学习笔记</title><meta name=keywords content><meta name=description content="
📋 一些基础概念


Stage 1:将虚拟地址 (VA) 转换为物理地址 (PA)（在非虚拟化环境下）或者转换为中间物理地址 (IPA)（在虚拟化环境下）。它主要受 OS 控制，用来做进程隔离。


Stage 2：将 IPA 转换为真正的 物理地址 (PA)。



为什么需要MMU？
裸机代码中CPU发送的地址直接发送到物理内存。但存在几个问题：

所有代码都能访问所有地址，没有保护
若跑多个Guest OS,地址会存在冲突
没法控制某段内存是 cacheable 还是 device 类型

MMU就是在CPU和物理内存中充当了翻译：CPU发送虚拟地址（VA），MMU通过查表翻译成物理地址（PA），同时附带权限和属性的信息。MMU查的这个表就是页表。
恒等映射：

恒等映射即虚拟地址=物理地址

先从恒等映射开始是因为：

从 BootLoader/BIOS 跳转到操作系统(如 Linux 内核)入口时,MMU 是关闭的。关闭了MMU 意味着不能利用高速缓存的性能。
MMU 关闭: 所有内存访问都是 Non-cacheable,每次访问主存 ~100+ cycles。
MMU 开启: 页表标记内存为 Cacheable,Cache 命中 ~3-5 cycles。
因此,我们在初始化的某个阶段需要把 MMU 打开并且使能数据高速缓存,以获得更高的性能。

但是MMU开启的瞬间，CPU发送的所有指令都会被翻译。如果VA≠PA，PC指向的地址会指向错误位置。这时候恒等映射就派上用场了，确保开启前后代码能正常运行
页表
假设有一个uint64_t table[512],通过index，数组返回一个值。页表原理类似，MMU拿到一个虚拟地址，从里面找到几个bit当作index，从页表去查数组，得到结果。如果一级数组来覆盖整个48-bit地址空间，需要2^48，不现实。
所以需要用到多级数组。4KB garanule是一个四维数组查找：

table_L0[i0] -> 指向table_L1
table_L1[i1] -> 指向table_L2
table_L2[i2] -> 指向table_L3
table_L3[i3] -> 最终的物理页地址







 




    
    
        
        为什么是 48-bit & 4级页表？
    
    
    
        1. 基础限制"><meta name=author content><link rel=canonical href=https://human-mean.github.io/posts/arm64-hypervisor%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/4.%E6%81%92%E7%AD%89%E6%98%A0%E5%B0%84mmu/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://human-mean.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://human-mean.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://human-mean.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://human-mean.github.io/apple-touch-icon.png><link rel=mask-icon href=https://human-mean.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://human-mean.github.io/posts/arm64-hypervisor%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/4.%E6%81%92%E7%AD%89%E6%98%A0%E5%B0%84mmu/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://human-mean.github.io/posts/arm64-hypervisor%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/4.%E6%81%92%E7%AD%89%E6%98%A0%E5%B0%84mmu/"><meta property="og:site_name" content="嵌入式学习笔记"><meta property="og:title" content="4.恒等映射MMU"><meta property="og:description" content=" 📋 一些基础概念
Stage 1:将虚拟地址 (VA) 转换为物理地址 (PA)（在非虚拟化环境下）或者转换为中间物理地址 (IPA)（在虚拟化环境下）。它主要受 OS 控制，用来做进程隔离。
Stage 2：将 IPA 转换为真正的 物理地址 (PA)。
为什么需要MMU？ 裸机代码中CPU发送的地址直接发送到物理内存。但存在几个问题：
所有代码都能访问所有地址，没有保护 若跑多个Guest OS,地址会存在冲突 没法控制某段内存是 cacheable 还是 device 类型 MMU就是在CPU和物理内存中充当了翻译：CPU发送虚拟地址（VA），MMU通过查表翻译成物理地址（PA），同时附带权限和属性的信息。MMU查的这个表就是页表。
恒等映射： 恒等映射即虚拟地址=物理地址
先从恒等映射开始是因为：
从 BootLoader/BIOS 跳转到操作系统(如 Linux 内核)入口时,MMU 是关闭的。关闭了MMU 意味着不能利用高速缓存的性能。 MMU 关闭: 所有内存访问都是 Non-cacheable,每次访问主存 ~100+ cycles。 MMU 开启: 页表标记内存为 Cacheable,Cache 命中 ~3-5 cycles。 因此,我们在初始化的某个阶段需要把 MMU 打开并且使能数据高速缓存,以获得更高的性能。
但是MMU开启的瞬间，CPU发送的所有指令都会被翻译。如果VA≠PA，PC指向的地址会指向错误位置。这时候恒等映射就派上用场了，确保开启前后代码能正常运行
页表 假设有一个uint64_t table[512],通过index，数组返回一个值。页表原理类似，MMU拿到一个虚拟地址，从里面找到几个bit当作index，从页表去查数组，得到结果。如果一级数组来覆盖整个48-bit地址空间，需要2^48，不现实。
所以需要用到多级数组。4KB garanule是一个四维数组查找：
table_L0[i0] -> 指向table_L1 table_L1[i1] -> 指向table_L2 table_L2[i2] -> 指向table_L3 table_L3[i3] -> 最终的物理页地址 为什么是 48-bit & 4级页表？ 1. 基础限制"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-03T00:00:00+00:00"><meta property="article:modified_time" content="2026-02-03T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="4.恒等映射MMU"><meta name=twitter:description content="
📋 一些基础概念


Stage 1:将虚拟地址 (VA) 转换为物理地址 (PA)（在非虚拟化环境下）或者转换为中间物理地址 (IPA)（在虚拟化环境下）。它主要受 OS 控制，用来做进程隔离。


Stage 2：将 IPA 转换为真正的 物理地址 (PA)。



为什么需要MMU？
裸机代码中CPU发送的地址直接发送到物理内存。但存在几个问题：

所有代码都能访问所有地址，没有保护
若跑多个Guest OS,地址会存在冲突
没法控制某段内存是 cacheable 还是 device 类型

MMU就是在CPU和物理内存中充当了翻译：CPU发送虚拟地址（VA），MMU通过查表翻译成物理地址（PA），同时附带权限和属性的信息。MMU查的这个表就是页表。
恒等映射：

恒等映射即虚拟地址=物理地址

先从恒等映射开始是因为：

从 BootLoader/BIOS 跳转到操作系统(如 Linux 内核)入口时,MMU 是关闭的。关闭了MMU 意味着不能利用高速缓存的性能。
MMU 关闭: 所有内存访问都是 Non-cacheable,每次访问主存 ~100+ cycles。
MMU 开启: 页表标记内存为 Cacheable,Cache 命中 ~3-5 cycles。
因此,我们在初始化的某个阶段需要把 MMU 打开并且使能数据高速缓存,以获得更高的性能。

但是MMU开启的瞬间，CPU发送的所有指令都会被翻译。如果VA≠PA，PC指向的地址会指向错误位置。这时候恒等映射就派上用场了，确保开启前后代码能正常运行
页表
假设有一个uint64_t table[512],通过index，数组返回一个值。页表原理类似，MMU拿到一个虚拟地址，从里面找到几个bit当作index，从页表去查数组，得到结果。如果一级数组来覆盖整个48-bit地址空间，需要2^48，不现实。
所以需要用到多级数组。4KB garanule是一个四维数组查找：

table_L0[i0] -> 指向table_L1
table_L1[i1] -> 指向table_L2
table_L2[i2] -> 指向table_L3
table_L3[i3] -> 最终的物理页地址







 




    
    
        
        为什么是 48-bit & 4级页表？
    
    
    
        1. 基础限制"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://human-mean.github.io/posts/"},{"@type":"ListItem","position":2,"name":"4.恒等映射MMU","item":"https://human-mean.github.io/posts/arm64-hypervisor%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/4.%E6%81%92%E7%AD%89%E6%98%A0%E5%B0%84mmu/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"4.恒等映射MMU","name":"4.恒等映射MMU","description":" 📋 一些基础概念\nStage 1:将虚拟地址 (VA) 转换为物理地址 (PA)（在非虚拟化环境下）或者转换为中间物理地址 (IPA)（在虚拟化环境下）。它主要受 OS 控制，用来做进程隔离。\nStage 2：将 IPA 转换为真正的 物理地址 (PA)。\n为什么需要MMU？ 裸机代码中CPU发送的地址直接发送到物理内存。但存在几个问题：\n所有代码都能访问所有地址，没有保护 若跑多个Guest OS,地址会存在冲突 没法控制某段内存是 cacheable 还是 device 类型 MMU就是在CPU和物理内存中充当了翻译：CPU发送虚拟地址（VA），MMU通过查表翻译成物理地址（PA），同时附带权限和属性的信息。MMU查的这个表就是页表。\n恒等映射： 恒等映射即虚拟地址=物理地址\n先从恒等映射开始是因为：\n从 BootLoader/BIOS 跳转到操作系统(如 Linux 内核)入口时,MMU 是关闭的。关闭了MMU 意味着不能利用高速缓存的性能。 MMU 关闭: 所有内存访问都是 Non-cacheable,每次访问主存 ~100+ cycles。 MMU 开启: 页表标记内存为 Cacheable,Cache 命中 ~3-5 cycles。 因此,我们在初始化的某个阶段需要把 MMU 打开并且使能数据高速缓存,以获得更高的性能。\n但是MMU开启的瞬间，CPU发送的所有指令都会被翻译。如果VA≠PA，PC指向的地址会指向错误位置。这时候恒等映射就派上用场了，确保开启前后代码能正常运行\n页表 假设有一个uint64_t table[512],通过index，数组返回一个值。页表原理类似，MMU拿到一个虚拟地址，从里面找到几个bit当作index，从页表去查数组，得到结果。如果一级数组来覆盖整个48-bit地址空间，需要2^48，不现实。\n所以需要用到多级数组。4KB garanule是一个四维数组查找：\ntable_L0[i0] -\u0026gt; 指向table_L1 table_L1[i1] -\u0026gt; 指向table_L2 table_L2[i2] -\u0026gt; 指向table_L3 table_L3[i3] -\u0026gt; 最终的物理页地址 为什么是 48-bit \u0026amp; 4级页表？ 1. 基础限制\n","keywords":[],"articleBody":" 📋 一些基础概念\nStage 1:将虚拟地址 (VA) 转换为物理地址 (PA)（在非虚拟化环境下）或者转换为中间物理地址 (IPA)（在虚拟化环境下）。它主要受 OS 控制，用来做进程隔离。\nStage 2：将 IPA 转换为真正的 物理地址 (PA)。\n为什么需要MMU？ 裸机代码中CPU发送的地址直接发送到物理内存。但存在几个问题：\n所有代码都能访问所有地址，没有保护 若跑多个Guest OS,地址会存在冲突 没法控制某段内存是 cacheable 还是 device 类型 MMU就是在CPU和物理内存中充当了翻译：CPU发送虚拟地址（VA），MMU通过查表翻译成物理地址（PA），同时附带权限和属性的信息。MMU查的这个表就是页表。\n恒等映射： 恒等映射即虚拟地址=物理地址\n先从恒等映射开始是因为：\n从 BootLoader/BIOS 跳转到操作系统(如 Linux 内核)入口时,MMU 是关闭的。关闭了MMU 意味着不能利用高速缓存的性能。 MMU 关闭: 所有内存访问都是 Non-cacheable,每次访问主存 ~100+ cycles。 MMU 开启: 页表标记内存为 Cacheable,Cache 命中 ~3-5 cycles。 因此,我们在初始化的某个阶段需要把 MMU 打开并且使能数据高速缓存,以获得更高的性能。\n但是MMU开启的瞬间，CPU发送的所有指令都会被翻译。如果VA≠PA，PC指向的地址会指向错误位置。这时候恒等映射就派上用场了，确保开启前后代码能正常运行\n页表 假设有一个uint64_t table[512],通过index，数组返回一个值。页表原理类似，MMU拿到一个虚拟地址，从里面找到几个bit当作index，从页表去查数组，得到结果。如果一级数组来覆盖整个48-bit地址空间，需要2^48，不现实。\n所以需要用到多级数组。4KB garanule是一个四维数组查找：\ntable_L0[i0] -\u003e 指向table_L1 table_L1[i1] -\u003e 指向table_L2 table_L2[i2] -\u003e 指向table_L3 table_L3[i3] -\u003e 最终的物理页地址 为什么是 48-bit \u0026 4级页表？ 1. 基础限制\n页大小 (Page Size): 4KB ($2^{12}$ Bytes)。 指针大小: ARM64 是 64 位系统，每个页表项 (PTE) 需 8 Bytes ($64 \\text{ bits}$)。 2. 单级页表容量计算 由于一页只有 4KB，所以一张页表能容纳的条目数为： $$\\frac{4096 \\text{ Bytes}}{8 \\text{ Bytes}} = 512 \\text{ Entries} = 2^9$$ 这意味着，每一级索引需要 9 bits ($2^9=512$)。\n3. 地址位宽推导 (4级页表) $$\\underbrace{9}{\\text{L0}} + \\underbrace{9}{\\text{L1}} + \\underbrace{9}{\\text{L2}} + \\underbrace{9}{\\text{L3}} + \\underbrace{12}_{\\text{Offset}} = \\mathbf{48 \\text{ bits}}$$\n4. 为什么不是 3 级？\n3级页表: $9+9+9+12 = 39 \\text{ bits}$。寻址范围 $2^{39} = 512 \\text{ GB}$ （明显不够用）。 4级页表: $48 \\text{ bits}$。寻址范围 $2^{48} = 256 \\text{ TB}$ 。 实现1GB Block mapping 这个是看最低的两位：\n当bit[0]等于0的时候，Descriptor是Invalid。 当bit[0]为1的时候，bit[1]为0则blcok（除了lv3），bit[1]为1的话就指向Table(下一级页表)。由于我们暂时先实现1GB的，暂时不用管lv3.![](images/bit_field.png 我们目前在跑EL1，没有用户态程序，选 AP = 00（PrivRead, PrivWrite）。\nAF: AF即Acess flag。\nAF 位用于告诉软件或硬件：这个页面最近是否被访问过。\nAF = 0的时候表示页面尚未访问。AF = 1表示页面已经被访问。\nAF的比特位是[10]。\nSH： SH 用来告诉硬件一块内存的数据，需要和谁保持一致。\nStage 1 Shareability attributes： SH[1:0] 普通内存 补充说明 00 Non-shareable 不共享。这块内存被视为只有当前 CPU 核在使用。硬件不会去窥探其他核的 Cache，其他核也看不到你的 Cache。 01 Reserved 10 Outer Shareable 外部共享。通常指数据需要在 CPU 簇（Cluster）之外也保持一致（例如与 GPU、DMA 等外设共享，取决于系统互联架构）。 11 Inner Shareable 内部共享。这是 SMP 系统的标准配置。表示所有运行同一个 OS/Hypervisor 的 CPU 核都能看到一致的数据。 SH的比特位是[9:8]。\nAttrIndx: AttrIndx 是一个查表索引\nMAIR_EL1 里有 8 个槽位（Attr0~Attr7），每个槽位定义一种内存类型。descriptor 里的 AttrIndx 告诉 CPU：“去第 N 个槽位查这块内存该怎么对待。”\n我们目前需要定义两个槽位，一个给 Device，一个给 Normal memory。然后不同的 block descriptor 用不同的 AttrIndx 值指过去。\n我们目前是4KB granule + Level 1 Block descriptor，所以只看这行：\nBlock[47:17] → OAB[47:30] → 4KB granule, level 1 Block descriptor. Descriptor bits [29:17] are RES0.\n[!NOTE] 由于 Hypervisor（EL2）通常只运行它自己，不涉及“子用户态”（除非开启了特定的虚拟化特性），所以 AP[1] 在这里被忽略了，只剩 AP[2] 起作用。 For a stage 1 translation that supports one Exception level, AP[1] is RES1.\nAP使用两个bit（Bits7:6）.对应了四种权限状态：\nAP[2:1] EL1权限 EL0权限 00 READ/WRITE None 01 READ/WRITE READ/WRITE 10 READ None 11 READ READ 可以看出，AP[2]对应EL1权限，AP[1]对应EL0权限。 现阶段我们的EL1权限给READ/WRITE。\nMAIR_EL1： MAIR_EL1 是 64 位寄存器，分成 8 个 8-bit 槽位（Attr0 ~ Attr7）。 0b0000dd00 Device memory. See encoding of ‘dd’ for the type of Device memory\ndevice memory,dd决定子类型。\noooo 高2位决定的是memory的cache策略类型，低2位决定的是allocate策略。\n我们需要Write-Back Non-transient, Read-Allocate, Write-Allocate\n高2位 = 0b11 (Normal memory, Outer Write-Back Non-transient.) R = 1, W = 1 （R/W miss时分配cache line） iiii 高2位决定的是memory的cache策略类型，低2位决定的是allocate策略。\n我们需要Write-Back Non-transient, Read-Allocate, Write-Allocate\n高2位 = 0b11 (Normal memory, Inner Write-Back Non-transient) R = 1, W = 1 （R/W miss时分配cache line） 0xooooiiii = 0b1111_1111 = 0xFF\nTCR_EL1: The control register for stage 1 of the EL1\u00260 translation regime. 用于 EL1 和 EL0 地址转换机制中，第一阶段（Stage 1）转换的控制寄存器。\nTOSZ: TTBR0_EL1所引用的内存区域的大小偏移量。该区域大小为2(64-T0SZ)字节。\n我们需要48-bit的虚拟地址空间,也就是说我们的TCR_EL1.T0SZ为16。\nTG0: 我们是4KB，TG0为0b00。\nSH0: 多核场景用Inner Shareable,0b11。\nORGN0/IRGN0: 这两个字都是CPU做页表walk时访问页表内存采用的cache策略。 因为页表在普通RAM里，所以页表work应当是cachable的。\n两者都选择0b01。\n总结TCR_EL1: TG0 = 0b00 [15:14] SH0 = 0b11 [13:12] ORGN0 = 0b01 [11:10] IRGN0 = 0b01 [9:8] TOSZ = 16 [5:0] 开启MMU步骤 1.配置MAIR_EL1 ：定义内存属性槽位 2.配置TCR_EL1：高速CPU页表格式，如granule、地址宽度 3.写入TTBR0_EL1:把Level 0页表的物理地址告诉CPU 4.SCTLR_EL1.M=1：开启MMU\nmmu.h\n#ifndef __MMU_H__ #define __MMU_H__ /* MAIR_EL1 */ #define MAIR_DEVICE_nGnRnE (0x00 \u003c\u003c 0) #define MAIR_NORMAL_WB (0xFF \u003c\u003c 8) #define MAIR_EL1_VALUE (MAIR_NORMAL_WB | \\ MAIR_DEVICE_nGnRnE) /* TCR_EL1 */ #define TCR_T0SZ (16UL \u003c\u003c 0) #define TCR_IRGN0 (0x01UL \u003c\u003c 8) #define TCR_ORGN0 (0x01UL \u003c\u003c 10) #define TCR_SH0 (0x03UL \u003c\u003c 12) #define TCR_TG0 (0x00UL \u003c\u003c 14) #define TCR_EL1_VALUE (TCR_T0SZ | \\ TCR_IRGN0 | \\ TCR_ORGN0 | \\ TCR_SH0 | \\ TCR_TG0) /* descriptor */ #define DESC_AP (0x00UL \u003c\u003c 6) #define DESC_AF (0X01UL \u003c\u003c 10) #define DESC_SH_INNER (0X03UL \u003c\u003c 8) #define DESC_SH_OUTER (0X02UL \u003c\u003c 8) #define DESC_ATTRINDX_DEVICE (0x00UL \u003c\u003c 2) #define DESC_ATTRINDX_NORMAL (0x01UL \u003c\u003c 2) #define DESC_BLOCK (0x01UL) #define DESC_TABLE (0x03UL) #endif ","wordCount":"540","inLanguage":"en","datePublished":"2026-02-03T00:00:00Z","dateModified":"2026-02-03T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://human-mean.github.io/posts/arm64-hypervisor%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/4.%E6%81%92%E7%AD%89%E6%98%A0%E5%B0%84mmu/"},"publisher":{"@type":"Organization","name":"嵌入式学习笔记","logo":{"@type":"ImageObject","url":"https://human-mean.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://human-mean.github.io/ accesskey=h title="嵌入式学习笔记 (Alt + H)">嵌入式学习笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><div class=post-wrapper><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">4.恒等映射MMU</h1><div class=post-meta><span title='2026-02-03 00:00:00 +0000 UTC'>February 3, 2026</span>&nbsp;·&nbsp;<span>3 min</span></div></header><div class=post-content><blockquote><p><strong>📋 一些基础概念</strong></p><ul><li><p><strong>Stage 1</strong>:将<strong>虚拟地址 (VA)</strong> 转换为<strong>物理地址 (PA)</strong>（在非虚拟化环境下）或者转换为<strong>中间物理地址 (IPA)</strong>（在虚拟化环境下）。它主要受 OS 控制，用来做进程隔离。</p></li><li><p><strong>Stage 2</strong>：将 <strong>IPA</strong> 转换为真正的 <strong>物理地址 (PA)</strong>。</p></li></ul></blockquote><h3 id=为什么需要mmu>为什么需要<strong>MMU</strong>？<a hidden class=anchor aria-hidden=true href=#为什么需要mmu>#</a></h3><p>裸机代码中CPU发送的地址直接发送到物理内存。但存在几个问题：</p><ul><li>所有代码都能访问所有地址，没有保护</li><li>若跑多个Guest OS,地址会存在冲突</li><li>没法控制某段内存是 cacheable 还是 device 类型</li></ul><p>MMU就是在CPU和物理内存中充当了翻译：CPU发送虚拟地址（VA），MMU通过查表翻译成物理地址（PA），同时附带权限和属性的信息。MMU查的这个表就是<strong>页表</strong>。</p><h4 id=恒等映射><strong>恒等映射</strong>：<a hidden class=anchor aria-hidden=true href=#恒等映射>#</a></h4><blockquote><p>恒等映射即虚拟地址=物理地址</p></blockquote><p>先从恒等映射开始是因为：</p><blockquote><p>从 BootLoader/BIOS 跳转到操作系统(如 Linux 内核)入口时,MMU 是关闭的。关闭了MMU 意味着不能利用高速缓存的性能。
<strong>MMU 关闭</strong>: 所有内存访问都是 Non-cacheable,每次访问主存 ~100+ cycles。
<strong>MMU 开启</strong>: 页表标记内存为 Cacheable,Cache 命中 ~3-5 cycles。
因此,我们在初始化的某个阶段需要把 MMU 打开并且使能数据高速缓存,以获得更高的性能。</p></blockquote><p><em><strong>但是MMU开启的瞬间，CPU发送的所有指令都会被翻译。如果VA≠PA，PC指向的地址会指向错误位置。这时候恒等映射就派上用场了，确保开启前后代码能正常运行</strong></em></p><h4 id=页表>页表<a hidden class=anchor aria-hidden=true href=#页表>#</a></h4><p>假设有一个<code>uint64_t table[512]</code>,通过index，数组返回一个值。页表原理类似，MMU拿到一个虚拟地址，从里面找到几个bit当作index，从页表去查数组，得到结果。如果一级数组来覆盖整个48-bit地址空间，需要2^48，不现实。</p><p>所以需要用到<strong>多级数组</strong>。4KB garanule是一个四维数组查找：</p><ul><li>table_L0[i0] -> 指向table_L1</li><li>table_L1[i1] -> 指向table_L2</li><li>table_L2[i2] -> 指向table_L3</li><li>table_L3[i3] -> 最终的物理页地址</li></ul><details open style="border:1px solid #448aff;border-left:4px solid #448aff;background-color:#f8f9fa;border-radius:4px;margin:1.5em 0;padding:0;overflow:hidden"><summary style="background-color:#448aff1a;padding:8px 12px;font-weight:700;cursor:pointer;color:#448aff;outline:none">为什么是 48-bit & 4级页表？</summary><div style=padding:15px;background:#fff;color:#333><p><strong>1. 基础限制</strong></p><ul><li><strong>页大小 (Page Size):</strong> 4KB ($2^{12}$ Bytes)。</li><li><strong>指针大小:</strong> ARM64 是 64 位系统，每个页表项 (PTE) 需 8 Bytes ($64 \text{ bits}$)。</li></ul><p><strong>2. 单级页表容量计算</strong>
由于一页只有 4KB，所以一张页表能容纳的条目数为：
$$\frac{4096 \text{ Bytes}}{8 \text{ Bytes}} = 512 \text{ Entries} = 2^9$$
这意味着，每一级索引需要 <strong>9 bits</strong> ($2^9=512$)。</p><p><strong>3. 地址位宽推导 (4级页表)</strong>
$$\underbrace{9}<em>{\text{L0}} + \underbrace{9}</em>{\text{L1}} + \underbrace{9}<em>{\text{L2}} + \underbrace{9}</em>{\text{L3}} + \underbrace{12}_{\text{Offset}} = \mathbf{48 \text{ bits}}$$</p><p><strong>4. 为什么不是 3 级？</strong></p><ul><li><strong>3级页表:</strong> $9+9+9+12 = 39 \text{ bits}$。寻址范围 $2^{39} = 512 \text{ GB}$ （明显不够用）。</li><li><strong>4级页表:</strong> $48 \text{ bits}$。寻址范围 $2^{48} = 256 \text{ TB}$ 。</li></ul></div></details><h3 id=实现1gb-block-mapping>实现1GB Block mapping<a hidden class=anchor aria-hidden=true href=#实现1gb-block-mapping>#</a></h3><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/Block_descriptor.png alt loading=lazy>
这个是看最低的两位：</p><ul><li>当bit[0]等于0的时候，Descriptor是Invalid。</li><li>当bit[0]为1的时候，bit[1]为0则blcok（除了lv3），bit[1]为1的话就指向Table(下一级页表)。由于我们暂时先实现1GB的，暂时不用管lv3.![](images/bit_field.png</li></ul><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/AP.png alt loading=lazy>
<img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/AP21%7d.png alt loading=lazy>
我们目前在跑EL1，没有用户态程序，选 <strong>AP = 00</strong>（PrivRead, PrivWrite）。</p><h4 id=af><strong>AF</strong>:<a hidden class=anchor aria-hidden=true href=#af>#</a></h4><p>AF即Acess flag。</p><p><strong>AF 位用于告诉软件或硬件：这个页面最近是否被访问过。</strong></p><p><code>AF = 0</code>的时候表示页面尚未访问。<code>AF = 1</code>表示页面已经被访问。</p><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/AF.png alt loading=lazy></p><p>AF的比特位是[10]。</p><h4 id=sh><strong>SH</strong>：<a hidden class=anchor aria-hidden=true href=#sh>#</a></h4><p><strong>SH 用来告诉硬件一块内存的数据，需要和谁保持一致。</strong></p><h6 id=stage-1-shareability-attributes><em>Stage 1 Shareability attributes：</em><a hidden class=anchor aria-hidden=true href=#stage-1-shareability-attributes>#</a></h6><table><thead><tr><th>SH[1:0]</th><th>普通内存</th><th>补充说明</th></tr></thead><tbody><tr><td>00</td><td>Non-shareable</td><td><strong>不共享</strong>。这块内存被视为只有当前 CPU 核在使用。硬件<strong>不会</strong>去窥探其他核的 Cache，其他核也看不到你的 Cache。</td></tr><tr><td>01</td><td>Reserved</td><td></td></tr><tr><td>10</td><td>Outer Shareable</td><td><strong>外部共享</strong>。通常指数据需要在 CPU 簇（Cluster）之外也保持一致（例如与 GPU、DMA 等外设共享，取决于系统互联架构）。</td></tr><tr><td>11</td><td>Inner Shareable</td><td><strong>内部共享</strong>。<strong>这是 SMP 系统的标准配置</strong>。表示所有运行同一个 OS/Hypervisor 的 CPU 核都能看到一致的数据。</td></tr></tbody></table><p>SH的比特位是[9:8]。</p><h3 id=attrindx><strong>AttrIndx</strong>:<a hidden class=anchor aria-hidden=true href=#attrindx>#</a></h3><p><strong>AttrIndx 是一个查表索引</strong></p><p>MAIR_EL1 里有 8 个槽位（Attr0~Attr7），每个槽位定义一种内存类型。descriptor 里的 AttrIndx 告诉 CPU：&ldquo;去第 N 个槽位查这块内存该怎么对待。&rdquo;</p><p>我们目前需要定义两个槽位，一个给 Device，一个给 Normal memory。然后不同的 block descriptor 用不同的 AttrIndx 值指过去。</p><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/Output%20Address.png alt loading=lazy>
我们目前是4KB granule + Level 1 Block descriptor，所以只看这行：</p><blockquote><p><strong>Block[47:17]</strong> → <strong>OAB[47:30]</strong> → 4KB granule, level 1 Block descriptor. Descriptor bits [29:17] are RES0.</p></blockquote><blockquote><p>[!NOTE]
由于 Hypervisor（EL2）通常只运行它自己，不涉及“子用户态”（除非开启了特定的虚拟化特性），所以 <strong>AP[1] 在这里被忽略了</strong>，只剩 <code>AP[2]</code> 起作用。
For a stage 1 translation that supports one Exception level, AP[1] is RES1.</p></blockquote><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/ap21.png alt loading=lazy>
<strong>AP</strong>使用两个bit（Bits7:6）.对应了四种权限状态：</p><table><thead><tr><th>AP[2:1]</th><th>EL1权限</th><th>EL0权限</th></tr></thead><tbody><tr><td>00</td><td>READ/WRITE</td><td>None</td></tr><tr><td>01</td><td>READ/WRITE</td><td>READ/WRITE</td></tr><tr><td>10</td><td>READ</td><td>None</td></tr><tr><td>11</td><td>READ</td><td>READ</td></tr><tr><td><strong>可以看出，AP[2]对应EL1权限，AP[1]对应EL0权限。</strong></td><td></td><td></td></tr></tbody></table><p>现阶段我们的EL1权限给READ/WRITE。</p><h4 id=mair_><strong>MAIR_EL1</strong>：<a hidden class=anchor aria-hidden=true href=#mair_>#</a></h4><p>MAIR_EL1 是 64 位寄存器，分成 8 个 8-bit 槽位（Attr0 ~ Attr7）。
<img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/MAIR_EL1.png alt loading=lazy></p><blockquote><p>0b0000dd00 Device memory. See encoding of ‘dd’ for the type of Device memory</p></blockquote><p>device memory,dd决定子类型。</p><h5 id=oooo><strong>oooo</strong><a hidden class=anchor aria-hidden=true href=#oooo>#</a></h5><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/oooo.png alt loading=lazy>
<strong>高2位</strong>决定的是memory的cache策略类型，<strong>低2位</strong>决定的是allocate策略。</p><p>我们需要<code>Write-Back Non-transient, Read-Allocate, Write-Allocate</code></p><ul><li>高2位 = 0b11 (Normal memory, Outer Write-Back Non-transient.)</li><li>R = 1, W = 1 （<em>R/W miss时分配cache line</em>）</li></ul><h5 id=iiii><strong>iiii</strong><a hidden class=anchor aria-hidden=true href=#iiii>#</a></h5><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/iiii_encode.png alt loading=lazy>
<strong>高2位</strong>决定的是memory的cache策略类型，<strong>低2位</strong>决定的是allocate策略。</p><p>我们需要<code>Write-Back Non-transient, Read-Allocate, Write-Allocate</code></p><ul><li>高2位 = 0b11 (<em>Normal memory, Inner Write-Back Non-transient</em>)</li><li>R = 1, W = 1 （<em>R/W miss时分配cache line</em>）</li><li><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/RW.png alt loading=lazy></li></ul><hr><p>0xooooiiii = <code>0b1111_1111</code> = <code>0xFF</code></p><h4 id=tcr_><strong>TCR_EL1:</strong><a hidden class=anchor aria-hidden=true href=#tcr_>#</a></h4><blockquote><p>The control register for stage 1 of the EL1&amp;0 translation regime.
用于 EL1 和 EL0 地址转换机制中，第一阶段（Stage 1）转换的控制寄存器。</p></blockquote><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/Pasted%20image%2020260212001108.png alt loading=lazy></p><hr><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/Pasted%20image%2020260212001728.png alt loading=lazy></p><h5 id=tosz><strong>TOSZ</strong>:<a hidden class=anchor aria-hidden=true href=#tosz>#</a></h5><p>TTBR0_EL1所引用的内存区域的大小偏移量。该区域大小为2(64-T0SZ)字节。</p><p>我们需要48-bit的虚拟地址空间,也就是说我们的<code>TCR_EL1.T0SZ</code>为16。</p><h5 id=tg0><strong>TG0</strong>:<a hidden class=anchor aria-hidden=true href=#tg0>#</a></h5><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/TG0.png alt loading=lazy>
我们是4KB，TG0为0b00。</p><h5 id=sh0><strong>SH0:</strong><a hidden class=anchor aria-hidden=true href=#sh0>#</a></h5><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/SH0.png alt loading=lazy>
多核场景用<code>Inner Shareable</code>,0b11。</p><h5 id=orgn0irgn0><strong>ORGN0/IRGN0:</strong><a hidden class=anchor aria-hidden=true href=#orgn0irgn0>#</a></h5><p><img src=/posts/ARM64%20Hypervisor%e5%ad%a6%e4%b9%a0%e8%ae%b0%e5%bd%95/images/ORGN0IRGN0.png alt loading=lazy>
这两个字都是CPU做页表walk时访问页表内存采用的<strong>cache策略</strong>。
因为页表在普通RAM里，所以页表work应当是cachable的。</p><p>两者都选择<code>0b01</code>。</p><h5 id=总结tcr_el1>总结TCR_EL1:<a hidden class=anchor aria-hidden=true href=#总结tcr_el1>#</a></h5><ul><li>TG0 = 0b00 [15:14]</li><li>SH0 = 0b11 [13:12]</li><li>ORGN0 = 0b01 [11:10]</li><li>IRGN0 = 0b01 [9:8]</li><li>TOSZ = 16 [5:0]</li></ul><h3 id=开启mmu步骤>开启MMU步骤<a hidden class=anchor aria-hidden=true href=#开启mmu步骤>#</a></h3><p>1.<strong>配置MAIR_EL1</strong> ：定义内存属性槽位
2.<strong>配置TCR_EL1</strong>：高速CPU页表格式，如granule、地址宽度
3.<strong>写入TTBR0_EL1</strong>:把Level 0页表的物理地址告诉CPU
4.<code>SCTLR_EL1.M=1</code>：开启MMU</p><p><strong>mmu.h</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-C data-lang=C><span style=display:flex><span><span style=color:#75715e>#ifndef __MMU_H__
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define __MMU_H__
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>/* MAIR_EL1 */</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#define MAIR_DEVICE_nGnRnE (0x00 &lt;&lt; 0)
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define MAIR_NORMAL_WB     (0xFF &lt;&lt; 8)
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#define MAIR_EL1_VALUE    (MAIR_NORMAL_WB | \
</span></span></span><span style=display:flex><span><span style=color:#75715e>                            MAIR_DEVICE_nGnRnE)
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>/* TCR_EL1 */</span>                            
</span></span><span style=display:flex><span><span style=color:#75715e>#define TCR_T0SZ           (16UL &lt;&lt; 0)
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define TCR_IRGN0          (0x01UL &lt;&lt; 8)
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define TCR_ORGN0          (0x01UL &lt;&lt; 10)
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define TCR_SH0            (0x03UL &lt;&lt; 12)
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define TCR_TG0            (0x00UL &lt;&lt; 14)
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#define TCR_EL1_VALUE (TCR_T0SZ  | \
</span></span></span><span style=display:flex><span><span style=color:#75715e>                      TCR_IRGN0  | \
</span></span></span><span style=display:flex><span><span style=color:#75715e>                      TCR_ORGN0  | \
</span></span></span><span style=display:flex><span><span style=color:#75715e>                      TCR_SH0 | \
</span></span></span><span style=display:flex><span><span style=color:#75715e>                      TCR_TG0)
</span></span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>/* descriptor */</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#define DESC_AP                 (0x00UL &lt;&lt; 6)
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define DESC_AF                 (0X01UL &lt;&lt; 10)     
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define DESC_SH_INNER           (0X03UL &lt;&lt; 8)
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define DESC_SH_OUTER           (0X02UL &lt;&lt; 8)
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define DESC_ATTRINDX_DEVICE    (0x00UL &lt;&lt; 2)  
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define DESC_ATTRINDX_NORMAL    (0x01UL &lt;&lt; 2)  
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define DESC_BLOCK              (0x01UL) 
</span></span></span><span style=display:flex><span><span style=color:#75715e>#define DESC_TABLE              (0x03UL) 
</span></span></span><span style=display:flex><span>                        
</span></span><span style=display:flex><span><span style=color:#75715e>#endif
</span></span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article><aside class=toc-sidebar><div class=toc-inner><details open><summary>目录</summary><nav id=TableOfContents><ul><li><ul><li><a href=#为什么需要mmu>为什么需要<strong>MMU</strong>？</a><ul><li><a href=#恒等映射><strong>恒等映射</strong>：</a></li><li><a href=#页表>页表</a></li></ul></li><li><a href=#实现1gb-block-mapping>实现1GB Block mapping</a><ul><li><a href=#af><strong>AF</strong>:</a></li><li><a href=#sh><strong>SH</strong>：</a><ul><li></li></ul></li></ul></li><li><a href=#attrindx><strong>AttrIndx</strong>:</a><ul><li><a href=#mair_><strong>MAIR_EL1</strong>：</a><ul><li><a href=#oooo><strong>oooo</strong></a></li><li><a href=#iiii><strong>iiii</strong></a></li></ul></li><li><a href=#tcr_><strong>TCR_EL1:</strong></a><ul><li><a href=#tosz><strong>TOSZ</strong>:</a></li><li><a href=#tg0><strong>TG0</strong>:</a></li><li><a href=#sh0><strong>SH0:</strong></a></li><li><a href=#orgn0irgn0><strong>ORGN0/IRGN0:</strong></a></li><li><a href=#总结tcr_el1>总结TCR_EL1:</a></li></ul></li></ul></li><li><a href=#开启mmu步骤>开启MMU步骤</a></li></ul></li></ul></nav></details></div></aside></div></main><footer class=footer><span>&copy; 2026 <a href=https://human-mean.github.io/>嵌入式学习笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>